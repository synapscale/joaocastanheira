# ğŸ” ConfiguraÃ§Ã£o de API Keys - Arquitetura SaaS Correta

## ğŸ—ï¸ **Arquitetura Implementada (CORRETA)**

```mermaid
graph TD
    A[Frontend Next.js] --> B[useChatContext]
    B --> C[chatService]
    C --> D[apiService]
    D --> E[Backend Robusto /api/v1/*]
    E --> F[User Variables - API Keys Criptografadas]
    E --> G[OpenAI API]
    E --> H[Anthropic API]
    E --> I[Google Gemini API]
    E --> J[Outros Provedores LLM]
```

## âœ… **Fluxo Correto Implementado:**

1. **UsuÃ¡rio** preenche API keys na pÃ¡gina `/user-variables`
2. **Backend** salva keys criptografadas no banco por usuÃ¡rio
3. **Chat** â†’ Frontend chama backend â†’ Backend usa keys do usuÃ¡rio
4. **LLM Response** â†’ Backend retorna resposta para frontend

## ğŸ”§ **ConfiguraÃ§Ãµes NecessÃ¡rias**

### 1. **VariÃ¡veis de Ambiente (.env.local)**

```env
# Backend da SynapScale (seu backend robusto)
NEXT_PUBLIC_API_URL=http://localhost:8000
NEXT_PUBLIC_WS_URL=ws://localhost:8000

# Ambiente da aplicaÃ§Ã£o
NEXT_PUBLIC_APP_ENV=development
```

### 2. **User Variables (PÃ¡gina /user-variables)**

O usuÃ¡rio deve configurar suas API keys na interface:

```bash
# API Keys dos Provedores LLM
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
GOOGLE_API_KEY=AIza...

# APIs de Ferramentas (opcionais)
TWITTER_API_KEY=...
LINKEDIN_API_KEY=...
INSTAGRAM_API_KEY=...
FACEBOOK_API_KEY=...
```

## ğŸ› ï¸ **Como Funciona a IntegraÃ§Ã£o**

### Frontend (Next.js)
```typescript
// hooks/use-chat.tsx usa useChatContext()
const { sendMessage } = useChatContext();

// Envia mensagem atravÃ©s do contexto
await sendMessage("OlÃ¡, como vocÃª estÃ¡?");
```

### Context Layer
```typescript
// context/chat-context.tsx usa chatService
const assistantMessage = await chatService.sendMessage(
  conversationId, 
  { content: message, attachments }
);
```

### Service Layer  
```typescript
// lib/services/chat.ts usa apiService
const response = await this.apiService.post(
  `/conversations/${conversationId}/messages`,
  messageData
);
```

### API Service
```typescript
// lib/api/service.ts faz chamada para backend
await fetch(`${API_BASE_URL}/api/v1/conversations/${id}/messages`, {
  method: 'POST',
  headers: { 'Authorization': `Bearer ${token}` },
  body: JSON.stringify(messageData)
});
```

### Backend (Seu Sistema Robusto)
```python
# Backend pega API keys do usuÃ¡rio do banco
user_variables = get_user_variables(user_id)
openai_key = decrypt(user_variables['OPENAI_API_KEY'])

# Faz chamada para LLM usando a key do usuÃ¡rio
response = openai.chat.completions.create(
    api_key=openai_key,
    model="gpt-4o",
    messages=[{"role": "user", "content": message}]
)
```

## ğŸš« **O que FOI REMOVIDO (Incorreto)**

- âŒ API Route `/app/api/chat/route.ts` (implementaÃ§Ã£o temporÃ¡ria)
- âŒ Chamadas diretas aos LLMs no frontend
- âŒ API keys expostas no Next.js

## âœ… **O que ESTÃ FUNCIONANDO (Correto)**

- âœ… Frontend chama apenas o backend do usuÃ¡rio
- âœ… Backend gerencia user variables (API keys criptografadas)
- âœ… Backend faz chamadas aos LLMs usando keys do usuÃ¡rio
- âœ… Arquitetura escalÃ¡vel e segura para SaaS

## ğŸ” **Endpoints da API (Seu Backend)**

### ConversaÃ§Ãµes
```bash
GET    /api/v1/conversations/              # Listar conversas
POST   /api/v1/conversations/              # Criar conversa
GET    /api/v1/conversations/{id}          # Obter conversa
DELETE /api/v1/conversations/{id}          # Deletar conversa
```

### Mensagens
```bash
GET  /api/v1/conversations/{id}/messages   # Listar mensagens
POST /api/v1/conversations/{id}/messages   # Enviar mensagem
```

### User Variables (API Keys)
```bash
GET    /api/v1/user-variables/             # Listar variÃ¡veis
POST   /api/v1/user-variables/             # Criar variÃ¡vel
PUT    /api/v1/user-variables/{id}         # Atualizar variÃ¡vel
DELETE /api/v1/user-variables/{id}         # Deletar variÃ¡vel
```

### LLM Generation
```bash
POST /api/v1/llm/generate                  # Gerar texto
POST /api/v1/llm/{provider}/generate       # Provedor especÃ­fico
GET  /api/v1/llm/providers                 # Listar provedores
GET  /api/v1/llm/models                    # Listar modelos
```

## ğŸ¯ **PrÃ³ximos Passos**

1. **âœ… Arquitetura Correta** - JÃ¡ implementada
2. **âš™ï¸ Configurar Backend** - Certifique-se que estÃ¡ rodando
3. **ğŸ” Configurar User Variables** - UsuÃ¡rio preenche API keys
4. **ğŸ§ª Testar IntegraÃ§Ã£o** - Enviar mensagens no chat
5. **ğŸ“Š Monitorar** - Verificar logs e mÃ©tricas

## ğŸ› **Troubleshooting**

### Chat nÃ£o funciona?
```bash
# 1. Verificar se backend estÃ¡ rodando
curl http://localhost:8000/health

# 2. Verificar autenticaÃ§Ã£o
curl -H "Authorization: Bearer $TOKEN" http://localhost:8000/api/v1/auth/me

# 3. Verificar user variables
curl -H "Authorization: Bearer $TOKEN" http://localhost:8000/api/v1/user-variables/
```

### Erro de API Keys?
- UsuÃ¡rio deve preencher keys em `/user-variables`
- Backend deve descriptografar e usar keys do usuÃ¡rio
- Verificar logs do backend para erros de integraÃ§Ã£o LLM

---

**âœ… Esta Ã© a arquitetura CORRETA para um SaaS profissional!** ğŸš€ 